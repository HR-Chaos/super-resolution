{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from FourierLoss import BandFilterLoss, BandFilterLossTorch, FourierHeatMap,FourierLossTorch\n",
    "from scipy.ndimage import convolve\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from neuralNet1 import NeuralNet1\n",
    "from neuralNet2 import NeuralNet2\n",
    "from neuralNet3 import NeuralNet3\n",
    "import helper_methods as HM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Number of available GPUs: 0\n",
      "Current device index: None\n",
      "Current device name: CPU\n"
     ]
    }
   ],
   "source": [
    "### Check if GPU is available\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Check for GPU availability and set device\n",
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    device = torch.device(\"cuda\")\n",
    "    current_device_idx = torch.cuda.current_device()\n",
    "else:\n",
    "    device_count = 0\n",
    "    device = torch.device(\"cpu\")\n",
    "    current_device_idx = None\n",
    "\n",
    "# Print device information\n",
    "print(f\"Number of available GPUs: {device_count}\")\n",
    "print(f\"Current device index: {current_device_idx}\")\n",
    "if device == torch.device(\"cuda\"):\n",
    "    print(f\"Current device name: {torch.cuda.get_device_name(current_device_idx)}\")\n",
    "else:\n",
    "    print(\"Current device name: CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Weights/NN_3_(weighted-fourier-mse).pth\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "weights = os.listdir(\"Model_Weights\")\n",
    "weight = \"Model_Weights/\"+weights[4]\n",
    "# model = NeuralNet1().to(device)#goes with checkpoint.pth-checkpoint2.pth\n",
    "# model = NeuralNet2().to(device)#goes with checkpoint3.pth\n",
    "model = NeuralNet3().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "checkpoint = torch.load(weight,map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.to(device)\n",
    "print(weight)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = plt.imread('HR_images/flickr_wild_000081.jpg')\n",
    "# s = 5.0\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(121)  # left side\n",
    "# ax2 = fig.add_subplot(122)  # right side\n",
    "# blurry_img = gaussian_filter(img,sigma=s)\n",
    "# ax1.imshow(img)\n",
    "# ax2.imshow(blurry_img)\n",
    "# plt.show()\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "# plt.imshow(blurry_img)\n",
    "# plt.show()\n",
    "\n",
    "fig,axes = plt.subplots(1,3,figsize=(12,4))\n",
    "img = plt.imread('extraPics/Mina.jpg')\n",
    "img = img[:684,:606,:]\n",
    "axes[0].imshow(img)\n",
    "kernel = np.ones((6,6),dtype=float)/36\n",
    "newimg = img.copy().astype(float)\n",
    "newimg[:,:,0] = (convolve(img[:,:,0],kernel))\n",
    "newimg[:,:,1] = (convolve(img[:,:,1],kernel))\n",
    "newimg[:,:,2] = (convolve(img[:,:,2],kernel))\n",
    "newimg = newimg/255\n",
    "axes[1].imshow(newimg)\n",
    "newimg = newimg[::6,::6,:]\n",
    "axes[2].imshow(newimg)\n",
    "plt.show()\n",
    "small_avgd_Mina = Image.fromarray((newimg*255).astype('uint8'))\n",
    "small_avgd_Mina.save('extraPics/small_avgd_Mina.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FUNCTIONS##\n",
    "def enhance(lr_image,display=False):#apply model to lr image\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    if type(lr_image)==str: image = plt.imread(lr_image)\n",
    "    elif type(lr_image)==np.ndarray: image = lr_image\n",
    "    else: print(\"Incorrect Input type to enhance funciton. Please put ndarray or file path to image\")\n",
    "    if np.max(image)<=1: image=(image*255).astype('uint8')\n",
    "    input_image = Image.fromarray(image)\n",
    "    input_image = transform(input_image)\n",
    "\n",
    "    # Perform the inference\n",
    "    with torch.no_grad():\n",
    "        input_image = input_image.to(device)  # Move the input image to the device\n",
    "        input_image = input_image.unsqueeze(0)  # Add a batch dimension\n",
    "        output = model(input_image)\n",
    "\n",
    "    output = output.squeeze(0).cpu().detach().numpy()# Convert to numpy array\n",
    "    output = np.transpose(output, (1, 2, 0))    # (C, H, W) to (H, W, C)\n",
    "    output = np.array(output,dtype=float)\n",
    "    if display:\n",
    "        fig,axes = plt.subplots(1,2,figsize=(16,8))\n",
    "        axes[0].imshow(image)\n",
    "        axes[0].set_title('LR Image')\n",
    "        axes[1].imshow(output)\n",
    "        axes[1].set_title('Generated Image')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        return output\n",
    "\n",
    "def double_quad_model(lr):\n",
    "    single_enhanced = enhance(lr)\n",
    "    double_quad = np.zeros((2048,2048,3),dtype=float)\n",
    "    double_quad[:1024,:1024,:] = enhance(single_enhanced[:256,:256,:])\n",
    "    double_quad[:1024,1024:,:] = enhance(single_enhanced[:256,256:,:])\n",
    "    double_quad[1024:,:1024,:] = enhance(single_enhanced[256:,:256,:])\n",
    "    double_quad[1024:,1024:,:] = enhance(single_enhanced[256:,256:,:])\n",
    "    return double_quad\n",
    "    tl = single_enhanced[:256,:256,:]\n",
    "    tr = single_enhanced[:256,256:,:]\n",
    "    bl = single_enhanced[256:,:256,:]\n",
    "    br = single_enhanced[256:,256:,:]\n",
    "    big_tl = enhance(tl)\n",
    "    big_tr = enhance(tr)\n",
    "    big_bl = enhance(bl)\n",
    "    big_br = enhance(br)\n",
    "    fig,axes = plt.subplots(2,2,figsize=(8,8))\n",
    "    axes[0][0].imshow(big_tl)\n",
    "    axes[0][1].imshow(big_tr)\n",
    "    axes[1][0].imshow(big_bl)\n",
    "    axes[1][1].imshow(big_br)\n",
    "    plt.show()\n",
    "    tl = big_tl[::4,::4,:]\n",
    "    tr = big_tr[::4,::4,:]\n",
    "    bl = big_bl[::4,::4,:]\n",
    "    br = big_br[::4,::4,:]\n",
    "    fig,axes = plt.subplots(2,2,figsize=(8,8))\n",
    "    axes[0][0].imshow(tl)\n",
    "    axes[0][1].imshow(tr)\n",
    "    axes[1][0].imshow(bl)\n",
    "    axes[1][1].imshow(br)\n",
    "    plt.show()\n",
    "    output = np.zeros_like(single_enhanced)\n",
    "    output[:256,:256,:] = tl\n",
    "    output[:256,256:,:] = tr\n",
    "    output[256:,:256,:] = bl\n",
    "    output[256:,256:,:] = br\n",
    "    \n",
    "    difference = abs(output-single_enhanced)\n",
    "    fig,axes = plt.subplots(1,3,figsize=(16,16))\n",
    "    axes[0].imshow(single_enhanced)\n",
    "    axes[0].set_title('Single Enhanced')\n",
    "    axes[1].imshow(output)\n",
    "    axes[1].set_title('Double Enhanced')\n",
    "    axes[2].imshow(difference)\n",
    "    axes[2].set_title('Difference')\n",
    "    plt.show()\n",
    "    return output\n",
    "\n",
    "def compute_metrics(target,generated,abs_difference,display=True):\n",
    "    t = transform(target.copy())#.copy() is just to get rid of the writability warning\n",
    "    o = transform(generated)\n",
    "    \n",
    "    mae = np.sum(abs_difference)/abs_difference.size\n",
    "    loss_mse = nn.MSELoss()\n",
    "    mse = loss_mse(t,o).item()#scale output back down to 0-1\n",
    "    \n",
    "    fourier_loss = FourierLossTorch()\n",
    "    fourier_mse = fourier_loss(t,o).item()#.copy() just to deal with writability warning\n",
    "    \n",
    "    t,o = skimage.img_as_ubyte(target),skimage.img_as_ubyte(generated)\n",
    "    ssim_score = ssim(t,o,data_range=o.max() - o.min(),channel_axis=2)\n",
    "    psnr_score = psnr(t,o)\n",
    "\n",
    "    if display:\n",
    "        print('MAE Loss:',mae)\n",
    "        print(\"MSE Loss:\",mse)\n",
    "        print(\"Fourier MSE:\",fourier_mse)\n",
    "        print(\"SSIM score:\", ssim_score)\n",
    "        print(\"PSNR score:\", psnr_score)\n",
    "    else:\n",
    "        return mse, fourier_mse,ssim_score,psnr_score\n",
    "\n",
    "def compare(input,target,output,model_name,difference_factors=[1]):#compares LR, HR, Generated from LR\n",
    "    #scale everything to 0-1\n",
    "    if np.max(input)>1: input_image = input/255\n",
    "    else: input_image = input\n",
    "    if np.max(target)>1: target_image = target/255\n",
    "    else: target_image = target\n",
    "    if np.max(output)>1: output_image = output/255\n",
    "    else: output_image = output\n",
    "    \n",
    "    difference_image = abs(output_image - target_image)\n",
    "    compute_metrics(target_image,output_image,difference_image)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3+len(difference_factors), figsize=(16+4*len(difference_factors), 8))\n",
    "    axes[0].imshow(input_image)\n",
    "    axes[0].set_title('LR Image')\n",
    "    axes[1].imshow(target_image)\n",
    "    axes[1].set_title('HR Image')\n",
    "    axes[2].imshow(output_image)\n",
    "    axes[2].set_title(model_name+' Upscale')\n",
    "    for i,factor in enumerate(difference_factors):\n",
    "        axes[i+3].imshow(difference_image*factor) # multiply by 2 to make the difference more visible\n",
    "        axes[i+3].set_title(\"Image Difference, factor \" + str(factor))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_fourier_maps(img,title,r,g,b):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 8))\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(title)\n",
    "    axes[1].imshow(r)\n",
    "    axes[1].set_title('R')\n",
    "    axes[2].imshow(g)\n",
    "    axes[2].set_title('G')\n",
    "    axes[3].imshow(b)\n",
    "    axes[3].set_title('B')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def fourier_map(img,title,display=True):\n",
    "    temp = img.copy()#just for dealing with writability warning\n",
    "    tensor = transform(temp)\n",
    "    tensor_fft = torch.fft.fftshift(torch.fft.fft2(tensor))\n",
    "    tensor_fft = torch.log(tensor_fft.real**2+tensor_fft.imag**2)\n",
    "\n",
    "    r_magnitude_spectrum = tensor_fft[0,:,:]\n",
    "    g_magnitude_spectrum = tensor_fft[1,:,:]\n",
    "    b_magnitude_spectrum = tensor_fft[2,:,:]\n",
    "\n",
    "    if display:\n",
    "        display_fourier_maps(img,title,r_magnitude_spectrum,g_magnitude_spectrum,b_magnitude_spectrum)\n",
    "    \n",
    "    return r_magnitude_spectrum,g_magnitude_spectrum,b_magnitude_spectrum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference and Analysis\n",
    "pictures = {\n",
    "    'tiger':(\"testing_dataset/downscaled_ci_flickr_wild_002021.jpg\",\"testing_dataset/flickr_wild_002021.jpg\"),\n",
    "    'dog':(\"testing_dataset/downscaled_ci_pixabay_dog_001489.jpg\",\"testing_dataset/pixabay_dog_001489.jpg\"),\n",
    "    'wolf':(\"testing_dataset/downscaled_ci_pixabay_wild_000639.jpg\",\"testing_dataset/pixabay_wild_000639.jpg\"),\n",
    "    'cat1':('testing_dataset/downscaled_ci_flickr_cat_000004.jpg','testing_dataset/flickr_cat_000004.jpg'),\n",
    "    'cat2':('testing_dataset/downscaled_ci_flickr_cat_000005.jpg','testing_dataset/flickr_cat_000005.jpg'),\n",
    "    'mufasa':('testing_dataset/downscaled_ci_pixabay_wild_000568.jpg','testing_dataset/pixabay_wild_000568.jpg'),\n",
    "    'scar':('testing_dataset/downscaled_ci_pixabay_wild_000561.jpg','testing_dataset/pixabay_wild_000561.jpg'),\n",
    "    'pastyScar':('LR_images/ci/downscaled_ci_flickr_wild_001704.jpg','HR_images/flickr_wild_001704.jpg'),\n",
    "    'monkeyLion':('testing_dataset/downscaled_ci_flickr_wild_001751.jpg','testing_dataset/flickr_wild_001751.jpg'),\n",
    "    'leopard':('testing_dataset/downscaled_ci_flickr_wild_002181.jpg','testing_dataset/flickr_wild_002181.jpg'),\n",
    "    'night_leopard':('testing_dataset/downscaled_ci_flickr_wild_002162.jpg','testing_dataset/flickr_wild_002162.jpg'),\n",
    "    'white_tiger':('testing_dataset/downscaled_ci_flickr_wild_000895.jpg','testing_dataset/flickr_wild_000895.jpg'),\n",
    "    'cub':('testing_dataset/downscaled_ci_flickr_wild_000812.jpg','testing_dataset/flickr_wild_000812.jpg'),#812-816\n",
    "    'kyri':('extraPics/LR_kitties5.jpg'),\n",
    "    'Mina':('extraPics/Mina.jpg'),\n",
    "    'small_cropped_Mina':('extraPics/small_cropped_Mina.jpg'),\n",
    "    'generated_Mina':('extraPics/generated_Mina.jpg'),\n",
    "    'small_generated_Mina':('extraPics/small_generated_Mina.jpg'),\n",
    "    'wave':(\"extraPics/downscaled_ci_waves.jpg\",\"extraPics/waves.jpg\"),\n",
    "    'noise':('extraPics/lr_noise.jpg','extraPics/hr_noise.jpg'),\n",
    "}\n",
    "\n",
    "lr, hr = pictures['wave']\n",
    "input,target = plt.imread(lr), plt.imread(hr)\n",
    "\n",
    "output = enhance(lr)\n",
    "print(\"Single Enhanced Metrics\")\n",
    "compare(input,target,output,\"Single_Enhanced\",difference_factors=[1])\n",
    "output = (output*255).astype('uint8')\n",
    "downscaled_image = cv2.resize(output, (128,128), interpolation=cv2.INTER_CUBIC)\n",
    "compare(input,input,downscaled_image,\"Downscaled_Enhanced_Image\",difference_factors=[8])\n",
    "# double_quad_enhanced = double_quad_model(lr)\n",
    "# print(\"Double Quad Enhanced Metrics\")\n",
    "# # compare(input,target,double_quad_enhanced,\"Double_Quad_Enhanced\",difference_factors=[1])\n",
    "\n",
    "# double_enhanced = enhance(enhance(lr))\n",
    "# print(\"Double Enhanced Metrics\")\n",
    "# compare(input,double_quad_enhanced,double_enhanced,\"Double_Enhanced\",difference_factors=[1])\n",
    "\n",
    "# bicubic_output =  np.array(HM.upscale_image_bicubic(lr,4))\n",
    "# print(\"Bicubic Metrics\")\n",
    "# compare(input,target,bicubic_output,\"Bicubic\")\n",
    "\n",
    "# enhance(pictures['Mina'],display=True)\n",
    "# enhance(pictures['small_cropped_Mina'],display=True)\n",
    "# enhance(pictures['generated_Mina'],display=True)#generated from upscale of small_cropped_Mina\n",
    "# enhance(pictures['small_generated_Mina'],display=True)#generated from downscaled of upscale of small_cropped mina\n",
    "# enhance('extraPics/small_avgd_Mina.jpg',display=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier Analysis\n",
    "\n",
    "difference = abs(target-output)\n",
    "# fourier_map(input,\"Input Image\",display=True)\n",
    "# rt,gt,bt = fourier_map(target,\"Target Image\",display=False)\n",
    "# ro,go,bo = fourier_map(output,\"Generated Image\",display=False)\n",
    "# display_fourier_maps(difference,\"Difference\",rt-ro,gt-go,bt-bo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some conv attempts -- Sobel Kernel##\n",
    "#image = transform.ToPILImage()(image)\n",
    "'''\n",
    "v_kernel is conv kernel to detect vertical edges, similar for h_kernel\n",
    "sobel kernel is a specific kernel that also detects edges\n",
    "'''\n",
    "# v_kernel = np.array([[[-2,-2,-2],[-1,-1,-1],[0,0,0],[1,1,1],[2,2,2]],\n",
    "#                      [[-2,-2,-2],[-1,-1,-1],[0,0,0],[1,1,1],[2,2,2]],\n",
    "#                      [[-2,-2,-2],[-1,-1,-1],[0,0,0],[1,1,1],[2,2,2]],\n",
    "#                      [[-2,-2,-2],[-1,-1,-1],[0,0,0],[1,1,1],[2,2,2]],\n",
    "#                      [[-2,-2,-2],[-1,-1,-1],[0,0,0],[1,1,1],[2,2,2]]])\n",
    "# v_kernel = np.array([[[-1,-1,-1],[0,0,0],[1,1,1]],\n",
    "#                      [[-2,-2,-2],[0,0,0],[2,2,2]],\n",
    "#                      [[-1,-1,-1],[0,0,0],[1,1,1]]])\n",
    "# h_kernel = np.transpose(v_kernel,(1,0,2))\n",
    "kernel = np.array([[[-1,-1,-1],[-1,-1,-1],[-1,-1,-1]],\n",
    "                     [[-1,-1,-1],[8,8,8],[-1,-1,-1]],\n",
    "                     [[-1,-1,-1],[-1,-1,-1],[-1,-1,-1]]])\n",
    "\n",
    "target = difference_image\n",
    "contrasted = convolve(target,kernel)\n",
    "plt.imshow(contrasted)\n",
    "plt.show()\n",
    "# target_v_edges = convolve(target, v_kernel)\n",
    "# target_h_edges = convolve(target,h_kernel)\n",
    "# target_avg = (target_v_edges + target_h_edges)//2\n",
    "\n",
    "# generated_v_edges = convolve(output_im, v_kernel)\n",
    "# generated_h_edges = convolve(output_im,h_kernel)\n",
    "# generated_avg = (generated_h_edges+generated_v_edges)//2\n",
    "# Create a figure with subplots\n",
    "# fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# # Display images in subplots\n",
    "# axes[0][0].imshow(target)\n",
    "# axes[0][0].set_title('Target Image')\n",
    "# axes[1][0].imshow(output_im)\n",
    "# axes[1][0].set_title('Generated Image')\n",
    "\n",
    "# axes[0][1].imshow(target_v_edges)\n",
    "# axes[0][1].set_title('Vertical Edges')\n",
    "# axes[1][1].imshow(generated_v_edges)\n",
    "# axes[1][1].set_title('Vertical Edges')\n",
    "\n",
    "# axes[0][2].imshow(target_h_edges)\n",
    "# axes[0][2].set_title('Horizontal Edges')\n",
    "# axes[1][2].imshow(generated_h_edges)\n",
    "# axes[1][2].set_title('Horizontal Edges')\n",
    "\n",
    "# axes[0][3].imshow(target_avg)\n",
    "# axes[0][3].set_title('Both Edges')\n",
    "# axes[1][3].imshow(generated_avg)\n",
    "# axes[1][3].set_title('Both Edges')\n",
    "\n",
    "# # Adjust spacing between subplots\n",
    "# plt.tight_layout()\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band Pass Fourier Filters \n",
    "\n",
    "def band_pass_channel(channel, mask,color):\n",
    "    #transform to frequency domain with FFT\n",
    "    f = np.fft.fft2(channel)\n",
    "    f_shift = np.fft.fftshift(f)\n",
    "    \n",
    "    #mask specific frequencies\n",
    "    f_shift_filtered = f_shift * mask\n",
    "    \n",
    "    #invert back to get new image\n",
    "    f_inverse_shift = np.fft.ifftshift(f_shift_filtered)\n",
    "    channel_filtered = np.fft.ifft2(f_inverse_shift)\n",
    "    channel_filtered = np.abs(channel_filtered).astype(int)#remove imaginary part, and make sure integers\n",
    "    return channel_filtered\n",
    "\n",
    "def band_pass_filter(img,r1,r2):\n",
    "\n",
    "    # Split the image into color channels\n",
    "    r = img[:,:,0]\n",
    "    g = img[:,:,1]\n",
    "    b = img[:,:,2]\n",
    "    \n",
    "    rows, cols, depth = img.shape\n",
    "    center_row, center_col = rows // 2, cols // 2#get center\n",
    "    \n",
    "    # # Create a circular mask\n",
    "    mask = np.zeros((rows, cols), np.uint8)#get rid of everything\n",
    "    mask = cv2.circle(mask, (center_col, center_row), r2, 1, -1)#actually keep disk of r2\n",
    "    if r1>0:\n",
    "        mask = cv2.circle(mask, (center_col, center_row), r1, 0, -1)    #actually get rid of inner disk again r1 (creating band)\n",
    "    # plt.imshow(mask,cmap='gray')\n",
    "    # plt.show()\n",
    "    # print(mask)\n",
    "    \n",
    "    #mask each color\n",
    "    r_filtered = band_pass_channel(r, mask,'R')\n",
    "    g_filtered = band_pass_channel(g, mask,'G')\n",
    "    b_filtered = band_pass_channel(b, mask,'B')\n",
    "    #combine to one image\n",
    "    filtered_image = cv2.merge((r_filtered, g_filtered, b_filtered))\n",
    "    return filtered_image,mask\n",
    "\n",
    "\n",
    "img = output_image\n",
    "plt.imshow(img)\n",
    "plt.title(\"Generated Image\")\n",
    "plt.show()\n",
    "fig, axes = plt.subplots(3,3,figsize=(12,12))\n",
    "for i in range(3):\n",
    "    # inner = (i*(i+19)**2)//400\n",
    "    inner=10\n",
    "    outer = inner+50*(i+1)\n",
    "    filtered,mask = band_pass_filter(img,inner,outer)\n",
    "    change = abs(filtered - img)\n",
    "    axes[i][0].imshow(filtered)\n",
    "    axes[i][0].set_title(\"Filtered: \" + str(inner)+\",\"+str(outer))\n",
    "    axes[i][1].imshow(change)\n",
    "    axes[i][1].set_title(\"Difference: \")\n",
    "    axes[i][2].imshow(mask,cmap='gray')\n",
    "    axes[i][2].set_title(\"Mask Used\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# filtered,mask = high_pass_filter(img,30,100)\n",
    "# plt.imshow(filtered)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between target and generated image band pass filter\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(12,12))\n",
    "axes[0].imshow(target_image)\n",
    "axes[0].set_title(\"Target Image\")\n",
    "axes[1].imshow(output_image)\n",
    "axes[1].set_title(\"Generated Image\")\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(2,4,figsize=(16,16))\n",
    "for i in range(2):\n",
    "    # inner = (i*(i+19)**2)//400\n",
    "    # outer = inner+100*(i+1)\n",
    "    inner= 0\n",
    "    outer = 75*i+75\n",
    "    target_filtered, target_mask = band_pass_filter(target_image,inner,outer)\n",
    "    output_filtered, output_mask = band_pass_filter(output_image,inner,outer)\n",
    "    change = abs(target_filtered - output_filtered)\n",
    "    axes[i][0].imshow(target_filtered)\n",
    "    axes[i][0].set_title(\"Filtered Target: \" + str(inner)+\",\"+str(outer))\n",
    "    axes[i][1].imshow(output_filtered)\n",
    "    axes[i][1].set_title(\"Filtered Output: \")\n",
    "    axes[i][2].imshow(change)\n",
    "    axes[i][2].set_title(\"difference:\")\n",
    "    axes[i][3].imshow(target_mask,cmap='gray')\n",
    "    axes[i][3].set_title(\"Mask Used\")\n",
    "    print(np.min(target_filtered),np.max(target_filtered))\n",
    "    # find MSE\n",
    "    mse = np.mean((change)**2)\n",
    "    print(\"MSE: \",mse)\n",
    "    # use HiFilterLoss to find mse\n",
    "    loss_fn = HiFilterLoss(inner,outer)\n",
    "    loss = loss_fn(target_image, output_image)\n",
    "    print(\"HiFilterLoss: \",loss)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# loss_fn2 = HiFilterLossTensor(20, 300)\n",
    "\n",
    "# target_image_tensor = transform(target_image)\n",
    "# output_image_tensor = transform(output_image)\n",
    "# loss = loss_fn2(target_image, output_image)\n",
    "# print(\"HiFilterLossTensor: \",loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss graphs\n",
    "def extract_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            if line.startswith(\" Epoch\"):\n",
    "                epoch = int(line.split(' ')[2])\n",
    "            if line.startswith('\\tBatch:'):\n",
    "                line_data = line.split('|')\n",
    "                batch_info = line_data[0].strip().split()\n",
    "                loss_info = line_data[1:-1]\n",
    "\n",
    "                batch = int(batch_info[1].split('/')[0])+epoch*938\n",
    "                loss_values = [info.strip().split(': ') for info in loss_info]\n",
    "\n",
    "                loss_dict = {key: float(value) for key, value in loss_values}\n",
    "                loss_dict['Batch'] = batch\n",
    "\n",
    "                data.append(loss_dict)\n",
    "\n",
    "    return data\n",
    "\n",
    "def graph_loss(data):\n",
    "    # Extracting the required values from the dictionary\n",
    "    batch = [entry['Batch'] for entry in data]\n",
    "    loss = [entry['Loss'] for entry in data]\n",
    "    mse_loss = [entry['MSE Loss'] for entry in data]\n",
    "    fourier_loss = [entry['Fourier Loss'] for entry in data]\n",
    "\n",
    "    # Plotting Loss vs Batch\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    plt.plot(batch, loss, label='Loss')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss vs Batch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting Mse loss vs Batch\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    plt.plot(batch, mse_loss, label='MSE Loss')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.title('MSE Loss vs Batch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting Fourier Loss vs Batch\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    plt.plot(batch, fourier_loss, label='Fourier Loss')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Fourier Loss')\n",
    "    plt.title('Fourier Loss vs Batch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "file_path = 'message.txt'\n",
    "extracted_data = extract_data(file_path)\n",
    "graph_loss(extracted_data)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
