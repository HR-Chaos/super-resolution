{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from customDataset import CustomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from neuralNet import NeuralNet\n",
    "from VGG import VGGLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Number of available GPUs: 1\n",
      "Current device index: 0\n",
      "Current device name: NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "### Check if GPU is available\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Check for GPU availability and set device\n",
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    device = torch.device(\"cuda\")\n",
    "    current_device_idx = torch.cuda.current_device()\n",
    "else:\n",
    "    device_count = 0\n",
    "    device = torch.device(\"cpu\")\n",
    "    current_device_idx = None\n",
    "\n",
    "# Print device information\n",
    "print(f\"Number of available GPUs: {device_count}\")\n",
    "print(f\"Current device index: {current_device_idx}\")\n",
    "print(f\"Current device name: {torch.cuda.get_device_name(current_device_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  60000\n"
     ]
    }
   ],
   "source": [
    "# Dataset creation\n",
    "# hyperparameters\n",
    "batch_size = 1\n",
    "train_X = \"LR_train\"\n",
    "train_y = \"HR_train\"\n",
    "val_X = \"LR_val\"\n",
    "val_y = \"HR_val\"\n",
    "test_X = \"LR_test\"\n",
    "test_y = \"HR_test\"\n",
    "\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Define a transformation operation to normalize the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_X, train_y, transform=transforms.ToTensor())\n",
    "val_dataset = CustomDataset(val_X, val_y, transform=transforms.ToTensor())\n",
    "test_dataset = CustomDataset(test_X, test_y, transform=transforms.ToTensor())\n",
    "\n",
    "print(\"dataset size: \", len(train_dataset))\n",
    "\n",
    "#### Create the dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hrita\\anaconda3\\envs\\dirac\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hrita\\anaconda3\\envs\\dirac\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#### Create the model\n",
    "model = NeuralNet()\n",
    "\n",
    "# create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# move them to device (GPU/CPU)\n",
    "model.to(device)\n",
    "\n",
    "# loss function\n",
    "loss_fn1 = VGGLoss(device)\n",
    "loss_fn2 = nn.MSELoss()\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      " Epoch: 0\n",
      " Batch: 0  Loss: 0.0\n",
      " Batch: 100  Loss: 4.688557260036468\n",
      " Batch: 200  Loss: 3.7292129468917845\n",
      " Batch: 300  Loss: 3.6385039615631105\n",
      " Batch: 400  Loss: 3.3535577178001406\n",
      " Batch: 500  Loss: 3.334996130466461\n",
      " Batch: 600  Loss: 3.550823941230774\n",
      " Batch: 700  Loss: 3.0672239577770233\n",
      " Batch: 800  Loss: 2.9988957762718202\n",
      " Batch: 900  Loss: 3.031031996011734\n",
      " Batch: 1000  Loss: 3.003542457818985\n",
      " Batch: 1100  Loss: 2.8836509478092194\n",
      " Batch: 1200  Loss: 2.9889648365974426\n",
      " Batch: 1300  Loss: 2.6362091267108916\n",
      " Batch: 1400  Loss: 2.7905691134929658\n",
      " Batch: 1500  Loss: 2.535564900636673\n",
      " Batch: 1600  Loss: 2.3231813514232638\n",
      " Batch: 1700  Loss: 2.3761431550979615\n",
      " Batch: 1800  Loss: 2.196658462882042\n",
      " Batch: 1900  Loss: 2.2896246725320815\n",
      " Batch: 2000  Loss: 2.1790716832876207\n",
      " Batch: 2100  Loss: 2.141760392785072\n",
      " Batch: 2200  Loss: 2.4221812403202057\n",
      " Batch: 2300  Loss: 2.268955955505371\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m     16\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m---> 17\u001b[0m batch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     19\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     20\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### Training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"------------------\\n Epoch: {epoch}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    batch_loss = 0\n",
    "    for i, (X, y) in enumerate(train_dataloader):\n",
    "        if i % 100 == 0:\n",
    "            print(\" Batch:\", i, \" Loss:\", batch_loss/100)\n",
    "            batch_loss = 0\n",
    "        \n",
    "        # retrieve data and move tensors to device\n",
    "        inputs = X.to(device)\n",
    "        labels = y.to(device)\n",
    "        \n",
    "        # calculate loss\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn1(outputs, labels)\n",
    "        loss+= loss_fn2(outputs, labels)\n",
    "        epoch_loss += loss.item()\n",
    "        batch_loss += loss.item()\n",
    "        \n",
    "        # zero gradient and backpropagate\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # change learning rate\n",
    "        if epoch/epochs > 0.5:\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "            \n",
    "        \n",
    "    # Print epoch information\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: Loss: {epoch_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(\u001b[39m\"\u001b[39m\u001b[39mLR_images/nn/downscaled_nn_flickr_cat_000742.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m image\u001b[39m.\u001b[39mshow()\n\u001b[1;32m----> 4\u001b[0m input_image \u001b[39m=\u001b[39m transform(image)\n\u001b[0;32m      6\u001b[0m \u001b[39m# # Load the trained model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# model = DeepImagePrior(input_shape)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# model.load_state_dict(torch.load(PATH_TO_SAVED_WEIGHTS))\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[39m# Set the model to evaluation mode\u001b[39;00m\n\u001b[0;32m     11\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "# Preprocess the input image\n",
    "image = Image.open(\"LR_images/nn/downscaled_nn_flickr_cat_000742.jpg\")\n",
    "image.show()\n",
    "input_image = transform(image)\n",
    "\n",
    "# # Load the trained model\n",
    "# model = DeepImagePrior(input_shape)\n",
    "# model.load_state_dict(torch.load(PATH_TO_SAVED_WEIGHTS))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform the inference\n",
    "with torch.no_grad():\n",
    "    input_image = input_image.to(device)  # Move the input image to the device\n",
    "    input_image = input_image.unsqueeze(0)  # Add a batch dimension\n",
    "    output = model(input_image)\n",
    "\n",
    "# Convert the output to a PIL image\n",
    "output = output.squeeze(0)\n",
    "output = transforms.ToPILImage()(output)\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel.pt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m model_name)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Load the model\u001b[39;00m\n\u001b[0;32m     11\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m model_name))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "### SAVE MODEL, LOAD MODEL, WORKS ANYWHERE ###\n",
    "##############################################\n",
    "\n",
    "model_name = \"model.pt\"\n",
    "\n",
    "# Save the model\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            }, 'checkpoint.pth')\n",
    "\n",
    "# Load the model\n",
    "new_model = NeuralNet()\n",
    "checkpoint = torch.load('checkpoint.pth')\n",
    "new_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
