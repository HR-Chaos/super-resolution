{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from customDataset import CustomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from neuralNet import NeuralNet\n",
    "from VGG import VGGLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Number of available GPUs: 0\n",
      "Current device index: None\n"
     ]
    }
   ],
   "source": [
    "### Check if GPU is available\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Check for GPU availability and set device\n",
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    device = torch.device(\"cuda\")\n",
    "    current_device_idx = torch.cuda.current_device()\n",
    "else:\n",
    "    device_count = 0\n",
    "    device = torch.device(\"cpu\")\n",
    "    current_device_idx = None\n",
    "\n",
    "# Print device information\n",
    "print(f\"Number of available GPUs: {device_count}\")\n",
    "print(f\"Current device index: {current_device_idx}\")\n",
    "# print(f\"Current device name: {torch.cuda.get_device_name(current_device_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size:  100\n",
      "val dataset size:  50\n",
      "test dataset size:  20\n"
     ]
    }
   ],
   "source": [
    "# Dataset creation\n",
    "# hyperparameters\n",
    "batch_size = 1\n",
    "train_X = \"LR_train\"\n",
    "train_y = \"HR_train\"\n",
    "val_X = \"LR_val\"\n",
    "val_y = \"HR_val\"\n",
    "test_X = \"LR_test\"\n",
    "test_y = \"HR_test\"\n",
    "\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Define a transformation operation to normalize the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_X, train_y, transform=transforms.ToTensor())\n",
    "val_dataset = CustomDataset(val_X, val_y, transform=transforms.ToTensor())\n",
    "test_dataset = CustomDataset(test_X, test_y, transform=transforms.ToTensor())\n",
    "\n",
    "print(\"train dataset size: \", len(train_dataset))\n",
    "print(\"val dataset size: \", len(val_dataset))\n",
    "print(\"test dataset size: \", len(test_dataset))\n",
    "\n",
    "#### Create the dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create the model\n",
    "model = NeuralNet()\n",
    "\n",
    "# create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# move them to device (GPU/CPU)\n",
    "model.to(device)\n",
    "\n",
    "# loss function\n",
    "loss_fn1 = VGGLoss(device)\n",
    "loss_fn2 = nn.MSELoss()\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'> Training\n",
      "\n",
      "------------------\n",
      " Epoch: 0\n",
      " Batch: 0  Loss: 0.0\n",
      "Epoch 1/10: Loss: 3229.5569\n",
      "------------------\n",
      " Epoch: 1\n",
      " Batch: 0  Loss: 0.0\n",
      "Epoch 2/10: Loss: 2063.8245\n",
      "------------------\n",
      " Epoch: 2\n",
      " Batch: 0  Loss: 0.0\n",
      "Epoch 3/10: Loss: 1868.1465\n",
      "------------------\n",
      " Epoch: 3\n",
      " Batch: 0  Loss: 0.0\n",
      "Epoch 4/10: Loss: 1641.2900\n",
      "------------------\n",
      " Epoch: 4\n",
      " Batch: 0  Loss: 0.0\n",
      "Epoch 5/10: Loss: 1578.2311\n",
      "------------------\n",
      " Epoch: 5\n",
      " Batch: 0  Loss: 0.0\n",
      "Epoch 6/10: Loss: 1544.1122\n",
      "------------------\n",
      " Epoch: 6\n",
      " Batch: 0  Loss: 0.0\n",
      "Epoch 7/10: Loss: 1411.2665\n",
      "------------------\n",
      " Epoch: 7\n",
      " Batch: 0  Loss: 0.0\n",
      "Epoch 8/10: Loss: 1337.3043\n",
      "------------------\n",
      " Epoch: 8\n",
      " Batch: 0  Loss: 0.0\n",
      "Epoch 9/10: Loss: 1324.5937\n",
      "------------------\n",
      " Epoch: 9\n",
      " Batch: 0  Loss: 0.0\n",
      "Epoch 10/10: Loss: 1321.1975\n"
     ]
    }
   ],
   "source": [
    "#### Training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"------------------\\n Epoch: {epoch}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    batch_loss = 0\n",
    "    for i, (X, y) in enumerate(train_dataloader):\n",
    "        if i % 100 == 0:\n",
    "            print(\" Batch:\", i, \" Loss:\", batch_loss/100)\n",
    "            batch_loss = 0\n",
    "        \n",
    "        # retrieve data and move tensors to device\n",
    "        inputs = X.to(device)\n",
    "        labels = y.to(device)\n",
    "        \n",
    "        # calculate loss\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn1(outputs, labels)\n",
    "        loss+= loss_fn2(outputs, labels)\n",
    "        epoch_loss += loss.item()\n",
    "        batch_loss += loss.item()\n",
    "        \n",
    "        # zero gradient and backpropagate\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # change learning rate\n",
    "        if epoch/epochs > 0.5:\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "            \n",
    "        \n",
    "    # Print epoch information\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: Loss: {epoch_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downscaled_ci_pixabay_dog_000045.jpg\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the input image\n",
    "pictures = os.listdir(\"LR_images/ci\")\n",
    "random.shuffle(pictures)\n",
    "print(pictures[0])\n",
    "# image = Image.open(os.path.join(\"LR_images/ci\",pictures[0]))\n",
    "# hr_image = Image.open(os.path.join(\"HR_images\",pictures[0][14:]))\n",
    "image = Image.open('downscaled_ci_waves.jpg')\n",
    "hr_image = Image.open('waves.jpg')\n",
    "image.show()\n",
    "hr_image.show()\n",
    "input_image = transform(image)\n",
    "\n",
    "# # Load the trained model\n",
    "# model = DeepImagePrior(input_shape)\n",
    "# model.load_state_dict(torch.load(PATH_TO_SAVED_WEIGHTS))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform the inference\n",
    "with torch.no_grad():\n",
    "    input_image = input_image.to(device)  # Move the input image to the device\n",
    "    input_image = input_image.unsqueeze(0)  # Add a batch dimension\n",
    "    output = model(input_image)\n",
    "\n",
    "# Convert the output to a PIL image\n",
    "output = output.squeeze(0)\n",
    "output = transforms.ToPILImage()(output)\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.9768, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "### SAVE MODEL, LOAD MODEL, WORKS ANYWHERE ###\n",
    "##############################################\n",
    "\n",
    "model_name = \"model.pt\"\n",
    "\n",
    "# Save the model\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            }, 'checkpoint.pth')\n",
    "\n",
    "# Load the model\n",
    "new_model = NeuralNet()\n",
    "checkpoint = torch.load('checkpoint.pth')\n",
    "new_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189274"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
